<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><style>body {
  max-width: 980px;
  margin: 16px auto;
}

body .markdown-body
{
  padding: 45px;
}

@font-face {
  font-family: fontawesome-mini;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #333333;
  overflow: hidden;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body b,
.markdown-body strong {
  font-weight: bold;
}

.markdown-body mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
.markdown-body sup {
  top: -0.5em;
}
.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body .codehilitetable,
.markdown-body .highlighttable {
  border: 0;
  border-spacing: 0;
}

.markdown-body .codehilitetable tr,
.markdown-body .highlighttable {
  border: 0;
}

.markdown-body .codehilitetable pre,
.markdown-body .codehilitetable div.codehilite,
.markdown-body .highlighttable pre,
.markdown-body .highlighttable div.highlight {
  margin: 0;
}

.markdown-body .linenos,
.markdown-body .code,
.markdown-body .codehilitetable td,
.markdown-body .highlighttable td {
  border: 0;
  padding: 0;
}

.markdown-body td:not(.linenos) .linenodiv {
  padding: 0 !important;
}

.markdown-body .code {
  width: 100%;
}

.markdown-body .linenos div pre,
.markdown-body .linenodiv pre,
.markdown-body .linenodiv {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-left-radius: 3px;
  -webkit-border-bottom-left-radius: 3px;
  -moz-border-radius-topleft: 3px;
  -moz-border-radius-bottomleft: 3px;
  border-top-left-radius: 3px;
  border-bottom-left-radius: 3px;
}

.markdown-body .code div pre,
.markdown-body .code div {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-right-radius: 3px;
  -webkit-border-bottom-right-radius: 3px;
  -moz-border-radius-topright: 3px;
  -moz-border-radius-bottomright: 3px;
  border-top-right-radius: 3px;
  border-bottom-right-radius: 3px;
}

.markdown-body * {
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body input {
  font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol";
  line-height: 1.4;
}

.markdown-body a {
  color: #4183c4;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:focus,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before,
.markdown-body hr:after {
  display: table;
  content: " ";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre,
.markdown-body samp {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #e7e7e7;
  background-image: -moz-linear-gradient(#fefefe, #e7e7e7);
  background-image: -webkit-linear-gradient(#fefefe, #e7e7e7);
  background-image: linear-gradient(#fefefe, #e7e7e7);
  background-repeat: repeat-x;
  border-radius: 2px;
  border: 1px solid #cfcfcf;
  color: #000;
  padding: 3px 5px;
  line-height: 10px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  display: inline-block;
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body .headerlink {
  font: normal 400 16px fontawesome-mini;
  vertical-align: middle;
  margin-left: -16px;
  float: left;
  display: inline-block;
  text-decoration: none;
  opacity: 0;
  color: #333;
}

.markdown-body .headerlink:focus {
  outline: none;
}

.markdown-body h1 .headerlink {
  margin-top: 0.8rem;
}

.markdown-body h2 .headerlink,
.markdown-body h3 .headerlink {
  margin-top: 0.6rem;
}

.markdown-body h4 .headerlink {
  margin-top: 0.2rem;
}

.markdown-body h5 .headerlink,
.markdown-body h6 .headerlink {
  margin-top: 0;
}

.markdown-body .headerlink:hover,
.markdown-body h1:hover .headerlink,
.markdown-body h2:hover .headerlink,
.markdown-body h3:hover .headerlink,
.markdown-body h4:hover .headerlink,
.markdown-body h5:hover .headerlink,
.markdown-body h6:hover .headerlink {
  opacity: 1;
  text-decoration: none;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body .admonition {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body code,
.markdown-body samp {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  border-radius: 3px;
}

.markdown-body code:not(.highlight):not(.codehilite), .markdown-body samp {
  background-color: rgba(0,0,0,0.04);
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .codehilite,
.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .codehilite pre,
.markdown-body .highlight pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
}

.markdown-body .codehilite,
.markdown-body .highlight,
.markdown-body pre {
  border-radius: 3px;
}

.markdown-body :not(.highlight) > pre {
  background-color: #f7f7f7;
}

.markdown-body .codehilite pre,
.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

/* Admonition */
.markdown-body .admonition {
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  position: relative;
  border-radius: 3px;
  border: 1px solid #e0e0e0;
  border-left: 6px solid #333;
  padding: 10px 10px 10px 30px;
}

.markdown-body .admonition table {
  color: #333;
}

.markdown-body .admonition p {
  padding: 0;
}

.markdown-body .admonition-title {
  font-weight: bold;
  margin: 0;
}

.markdown-body .admonition>.admonition-title {
  color: #333;
}

.markdown-body .attention>.admonition-title {
  color: #a6d796;
}

.markdown-body .caution>.admonition-title {
  color: #d7a796;
}

.markdown-body .hint>.admonition-title {
  color: #96c6d7;
}

.markdown-body .danger>.admonition-title {
  color: #c25f77;
}

.markdown-body .question>.admonition-title {
  color: #96a6d7;
}

.markdown-body .note>.admonition-title {
  color: #d7c896;
}

.markdown-body .admonition:before,
.markdown-body .attention:before,
.markdown-body .caution:before,
.markdown-body .hint:before,
.markdown-body .danger:before,
.markdown-body .question:before,
.markdown-body .note:before {
  font: normal normal 16px fontawesome-mini;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  line-height: 1.5;
  color: #333;
  position: absolute;
  left: 0;
  top: 0;
  padding-top: 10px;
  padding-left: 10px;
}

.markdown-body .admonition:before {
  content: "\f056\00a0";
  color: 333;
}

.markdown-body .attention:before {
  content: "\f058\00a0";
  color: #a6d796;
}

.markdown-body .caution:before {
  content: "\f06a\00a0";
  color: #d7a796;
}

.markdown-body .hint:before {
  content: "\f05a\00a0";
  color: #96c6d7;
}

.markdown-body .danger:before {
  content: "\f057\00a0";
  color: #c25f77;
}

.markdown-body .question:before {
  content: "\f059\00a0";
  color: #96a6d7;
}

.markdown-body .note:before {
  content: "\f040\00a0";
  color: #d7c896;
}

.markdown-body .admonition::after {
  content: normal;
}

.markdown-body .attention {
  border-left: 6px solid #a6d796;
}

.markdown-body .caution {
  border-left: 6px solid #d7a796;
}

.markdown-body .hint {
  border-left: 6px solid #96c6d7;
}

.markdown-body .danger {
  border-left: 6px solid #c25f77;
}

.markdown-body .question {
  border-left: 6px solid #96a6d7;
}

.markdown-body .note {
  border-left: 6px solid #d7c896;
}

.markdown-body .admonition>*:first-child {
  margin-top: 0 !important;
}

.markdown-body .admonition>*:last-child {
  margin-bottom: 0 !important;
}

/* progress bar*/
.markdown-body .progress {
  display: block;
  width: 300px;
  margin: 10px 0;
  height: 24px;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #ededed;
  position: relative;
  box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1);
}

.markdown-body .progress-label {
  position: absolute;
  text-align: center;
  font-weight: bold;
  width: 100%; margin: 0;
  line-height: 24px;
  color: #333;
  text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000;
  -webkit-font-smoothing: antialiased !important;
  white-space: nowrap;
  overflow: hidden;
}

.markdown-body .progress-bar {
  height: 24px;
  float: left;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #96c6d7;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1);
  background-size: 30px 30px;
  background-image: -webkit-linear-gradient(
    135deg, rgba(255, 255, 255, .4) 27%,
    transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%,
    transparent 77%, transparent
  );
  background-image: -moz-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -ms-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -o-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
}

.markdown-body .progress-100plus .progress-bar {
  background-color: #a6d796;
}

.markdown-body .progress-80plus .progress-bar {
  background-color: #c6d796;
}

.markdown-body .progress-60plus .progress-bar {
  background-color: #d7c896;
}

.markdown-body .progress-40plus .progress-bar {
  background-color: #d7a796;
}

.markdown-body .progress-20plus .progress-bar {
  background-color: #d796a6;
}

.markdown-body .progress-0plus .progress-bar {
  background-color: #c25f77;
}

.markdown-body .candystripe-animate .progress-bar{
  -webkit-animation: animate-stripes 3s linear infinite;
  -moz-animation: animate-stripes 3s linear infinite;
  animation: animate-stripes 3s linear infinite;
}

@-webkit-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@-moz-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

.markdown-body .gloss .progress-bar {
  box-shadow:
    inset 0 4px 12px rgba(255, 255, 255, .7),
    inset 0 -12px 0 rgba(0, 0, 0, .05);
}

/* MultiMarkdown Critic Blocks */
.markdown-body .critic_mark {
  background: #ff0;
}

.markdown-body .critic_delete {
  color: #c82829;
  text-decoration: line-through;
}

.markdown-body .critic_insert {
  color: #718c00 ;
  text-decoration: underline;
}

.markdown-body .critic_comment {
  color: #8e908c;
  font-style: italic;
}

.markdown-body .headeranchor {
  font: normal normal 16px fontawesome-mini;
  line-height: 1;
  display: inline-block;
  text-decoration: none;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.headeranchor:before {
  content: '\e157';
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 4px 0.25em -20px;
  vertical-align: middle;
}

.markdown-body diagram-div, .markdown-body div.uml-sequence-diagram, .markdown-body, div.uml-flowchart {
  overflow: auto;
}

/* Media */
@media only screen and (min-width: 480px) {
  .markdown-body {
    font-size:14px;
  }
}

@media only screen and (min-width: 768px) {
  .markdown-body {
    font-size:16px;
  }
}

@media print {
  .markdown-body * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
    -ms-filter: none !important;
  }

  .markdown-body {
    font-size:12pt;
    max-width:100%;
    outline:none;
    border: 0;
  }

  .markdown-body a,
  .markdown-body a:visited {
    text-decoration: underline;
  }

  .markdown-body .headeranchor-link {
    display: none;
  }

  .markdown-body a[href]:after {
    content: " (" attr(href) ")";
  }

  .markdown-body abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .markdown-body .ir a:after,
  .markdown-body a[href^="javascript:"]:after,
  .markdown-body a[href^="#"]:after {
    content: "";
  }

  .markdown-body pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .markdown-body pre,
  .markdown-body blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  .markdown-body .progress,
  .markdown-body .progress-bar {
    -moz-box-shadow: none;
    -webkit-box-shadow: none;
    box-shadow: none;
  }

  .markdown-body .progress {
    border: 1px solid #ddd;
  }

  .markdown-body .progress-bar {
    height: 22px;
    border-right: 1px solid #ddd;
  }

  .markdown-body tr,
  .markdown-body img {
    page-break-inside: avoid;
  }

  .markdown-body img {
    max-width: 100% !important;
  }

  .markdown-body p,
  .markdown-body h2,
  .markdown-body h3 {
    orphans: 3;
    widows: 3;
  }

  .markdown-body h2,
  .markdown-body h3 {
    page-break-after: avoid;
  }
}
</style><style>/*GitHub*/
.highlight {background-color:#f7f7f7;color:#333333;}
.highlight .hll {background-color:#ffffcc;}
.highlight .c{color:#999988;font-style:italic}
.highlight .err{color:#a61717;background-color:#e3d2d2}
.highlight .k{font-weight:bold}
.highlight .o{font-weight:bold}
.highlight .cm{color:#999988;font-style:italic}
.highlight .cp{color:#999999;font-weight:bold}
.highlight .c1{color:#999988;font-style:italic}
.highlight .cs{color:#999999;font-weight:bold;font-style:italic}
.highlight .gd{color:#000000;background-color:#ffdddd}
.highlight .ge{font-style:italic}
.highlight .gr{color:#aa0000}
.highlight .gh{color:#999999}
.highlight .gi{color:#000000;background-color:#ddffdd}
.highlight .go{color:#888888}
.highlight .gp{color:#555555}
.highlight .gs{font-weight:bold}
.highlight .gu{color:#800080;font-weight:bold}
.highlight .gt{color:#aa0000}
.highlight .kc{font-weight:bold}
.highlight .kd{font-weight:bold}
.highlight .kn{font-weight:bold}
.highlight .kp{font-weight:bold}
.highlight .kr{font-weight:bold}
.highlight .kt{color:#445588;font-weight:bold}
.highlight .m{color:#009999}
.highlight .s{color:#dd1144}
.highlight .n{color:#333333}
.highlight .na{color:teal}
.highlight .nb{color:#0086b3}
.highlight .nc{color:#445588;font-weight:bold}
.highlight .no{color:teal}
.highlight .ni{color:purple}
.highlight .ne{color:#990000;font-weight:bold}
.highlight .nf{color:#990000;font-weight:bold}
.highlight .nn{color:#555555}
.highlight .nt{color:navy}
.highlight .nv{color:teal}
.highlight .ow{font-weight:bold}
.highlight .w{color:#bbbbbb}
.highlight .mf{color:#009999}
.highlight .mh{color:#009999}
.highlight .mi{color:#009999}
.highlight .mo{color:#009999}
.highlight .sb{color:#dd1144}
.highlight .sc{color:#dd1144}
.highlight .sd{color:#dd1144}
.highlight .s2{color:#dd1144}
.highlight .se{color:#dd1144}
.highlight .sh{color:#dd1144}
.highlight .si{color:#dd1144}
.highlight .sx{color:#dd1144}
.highlight .sr{color:#009926}
.highlight .s1{color:#dd1144}
.highlight .ss{color:#990073}
.highlight .bp{color:#999999}
.highlight .vc{color:teal}
.highlight .vg{color:teal}
.highlight .vi{color:teal}
.highlight .il{color:#009999}
.highlight .gc{color:#999;background-color:#EAF2F5}
</style><title>residual_connections</title></head><body><article class="markdown-body"><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['$$', '$$']]
      }
    };
</script>

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: true });
</script>

<h1 id="do-you-really-understand-residual-links">Do You Really Understand Residual Links?<a class="headerlink" href="#do-you-really-understand-residual-links" title="Permanent link"></a></h1>
<p>Welcome to my understanding on residual links. Most people will likely provide the following explanation when asked about residual links and why they are useful: <code>"Residual links, also called skip connections, allow the input to skip over some layers and be added to the output of those layers. This helps address the degradation problem, where adding more layers to a neural network can actually decrease its performance. Residual links make it easier to train very deep neural networks by facilitating better information flow and mitigating issues like vanishing/exploding gradients."</code></p>
<p>These also will likely satisfy your interviewer when they ask about residual links. Just rattle off those surface-level explanations about skip connections and degradation problems, maybe throw in some jargon like &lsquo;vanishing gradients&rsquo; and &lsquo;feature reuse&rsquo; to sound smart. That&rsquo;s all it takes to check the box and move on, right? After all, who really needs to deeply understand the core concepts and math behind residual networks? The answer will likely be enough to convince the interviewer you know what you&rsquo;re talking about, even if it&rsquo;s mostly regurgitated fluff.
Or maybe your interviewer does not even know what he is asking about.</p>
<h2 id="implementation-to-show-vanishing-gradient-and-the-effect-of-having-a-residual-link">Implementation to Show Vanishing Gradient and the Effect of Having a Residual Link<a class="headerlink" href="#implementation-to-show-vanishing-gradient-and-the-effect-of-having-a-residual-link" title="Permanent link"></a></h2>
<p>The CustomDeepNetwork class demonstrates the implementation of residual connections. The use_residual parameter determines whether the shortcut connections are applied. When use_residual is set to True, the input x is added to the output of each layer if their shapes match, creating a residual connection. </p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">CustomDeepNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">use_residual</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomDeepNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_residual</span> <span class="o">=</span> <span class="n">use_residual</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
            <span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_residual</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">output</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">output</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Define the sizes of each layer</span>
<span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># Initialize the model with residual connections</span>
<span class="n">model_with_residual</span> <span class="o">=</span> <span class="n">CustomDeepNetwork</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">,</span> <span class="n">use_residual</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">model_without_residual</span> <span class="o">=</span> <span class="n">CustomDeepNetwork</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">,</span> <span class="n">use_residual</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">display_gradients</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
    <span class="c1"># Perform a forward pass through the model</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>

    <span class="c1"># Compute the mean squared error loss</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">loss_value</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

    <span class="c1"># Perform a backward pass to compute gradients</span>
    <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Iterate through model parameters and print gradients</span>
    <span class="k">for</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="s">&#39;weight&#39;</span> <span class="ow">in</span> <span class="n">param_name</span><span class="p">:</span>
            <span class="c1"># Print the gradient values and their mean absolute value</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">&quot;Mean absolute gradient of {param_name}: {parameter.grad.abs().mean().item()}&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
<span class="n">sample_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>


<span class="n">display_gradients</span><span class="p">(</span><span class="n">model_with_residual</span><span class="p">,</span> <span class="n">sample_input</span><span class="p">)</span>
</pre></div>

<div class="highlight"><pre><span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.0.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.015456237830221653</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.1.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.0082783168181777</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.2.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.01303770300000906</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.3.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.00975505169481039</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.4.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.004205979872494936</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.5.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.003670105943456292</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.6.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.03035895712673664</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.7.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.03344191983342171</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.8.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.045371200889348984</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.9.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.0</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.10.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.026721157133579254</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.11.0.weight</span><span class="o">:</span> <span class="nt">6</span><span class="nc">.576962186954916e-05</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.12.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.42710962891578674</span>
</pre></div>

<div class="highlight"><pre><span class="n">display_gradients</span><span class="p">(</span><span class="n">model_without_residual</span><span class="p">,</span> <span class="n">sample_input</span><span class="p">)</span>
</pre></div>

<div class="highlight"><pre><span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.0.0.weight</span><span class="o">:</span> <span class="nt">1</span><span class="nc">.3087806394196377e-08</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.1.0.weight</span><span class="o">:</span> <span class="nt">4</span><span class="nc">.8706940702913926e-09</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.2.0.weight</span><span class="o">:</span> <span class="nt">9</span><span class="nc">.519102839306015e-09</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.3.0.weight</span><span class="o">:</span> <span class="nt">4</span><span class="nc">.560284949661764e-08</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.4.0.weight</span><span class="o">:</span> <span class="nt">1</span><span class="nc">.5104563999557286e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.5.0.weight</span><span class="o">:</span> <span class="nt">6</span><span class="nc">.48931120394991e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.6.0.weight</span><span class="o">:</span> <span class="nt">4</span><span class="nc">.181424628768582e-06</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.7.0.weight</span><span class="o">:</span> <span class="nt">6</span><span class="nc">.420085355784977e-06</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.8.0.weight</span><span class="o">:</span> <span class="nt">1</span><span class="nc">.6240186596405692e-05</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.9.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.00020436437625903636</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.10.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.00020677836437243968</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.11.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.0010400100145488977</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.12.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.01473889872431755</span>
</pre></div>

<p>In our experiments with <code>CustomDeepNetwork</code>, we observed that the vanishing gradient problem is more pronounced in models without residual connections compared to those with residual connections. This phenomenon can be attributed to the way gradients are propagated through layers during backpropagation in standard deep networks. Without residual connections, the gradients are sequentially multiplied through many layers. When small gradients are multiplied together, they can diminish exponentially, leading to the vanishing gradient problem.</p>
<p>Residual connections introduce skip connections or shortcuts that enable gradients to bypass certain layers during backpropagation. This mechanism indeed mitigates the vanishing gradient problem.</p>
<p>Interestingly, our experiments with <code>CustomDeepNetwork</code> also revealed that increasing the width of each layer can help alleviate the vanishing gradient problem to some extent.</p>
<p>Let&rsquo;s explore the following setup further:</p>
<div class="highlight"><pre><span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">1024</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">display_gradients</span><span class="p">(</span><span class="n">model_with_residual</span><span class="p">,</span> <span class="n">sample_input</span><span class="p">)</span>
</pre></div>

<p><div class="highlight"><pre><span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.0.0.weight</span><span class="o">:</span> <span class="nt">4</span><span class="nc">.922050607092388e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.1.0.weight</span><span class="o">:</span> <span class="nt">2</span><span class="nc">.632298787830223e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.2.0.weight</span><span class="o">:</span> <span class="nt">2</span><span class="nc">.0730938388169307e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.3.0.weight</span><span class="o">:</span> <span class="nt">3</span><span class="nc">.326572368678171e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.4.0.weight</span><span class="o">:</span> <span class="nt">7</span><span class="nc">.172093319240957e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.5.0.weight</span><span class="o">:</span> <span class="nt">3</span><span class="nc">.7833722217328614e-06</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.6.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.00021849258337169886</span>
</pre></div>
<div class="highlight"><pre><span class="n">display_gradients</span><span class="p">(</span><span class="n">model_without_residual</span><span class="p">,</span> <span class="n">sample_input</span><span class="p">)</span>
</pre></div>
<div class="highlight"><pre><span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.0.0.weight</span><span class="o">:</span> <span class="nt">6</span><span class="nc">.812519472987333e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.1.0.weight</span><span class="o">:</span> <span class="nt">3</span><span class="nc">.5042324952883064e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.2.0.weight</span><span class="o">:</span> <span class="nt">2</span><span class="nc">.8378119054650597e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.3.0.weight</span><span class="o">:</span> <span class="nt">4</span><span class="nc">.569472196180868e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.4.0.weight</span><span class="o">:</span> <span class="nt">9</span><span class="nc">.6639780622354e-07</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.5.0.weight</span><span class="o">:</span> <span class="nt">6</span><span class="nc">.078783826524159e-06</span>
<span class="nt">Mean</span> <span class="nt">absolute</span> <span class="nt">gradient</span> <span class="nt">of</span> <span class="nt">layers</span><span class="nc">.6.0.weight</span><span class="o">:</span> <span class="nt">0</span><span class="nc">.0004158136434853077</span>
</pre></div></p>
<p>It seems that the effect of the residual link has disappeared.</p>
<p>The common explanation of residual connections often describes them using the 
formulation $f(x)+x$ and its derivative with respect to $x$. However, this explanation frequently falls short in clarifying what these terms actually 
represent and how residual links fundamentally improve optimization.</p>
<p>Since the historical breakthrough of AlexNet in 2012, until the emergence of GoogLeNet, the major advancements in mainstream network structures 
have been primarily focused on making networks deeper (more layers) and wider (more neurons).
However, simply increasing the size of the network has its drawbacks:</p>
<ul>
<li>Too many parameters can lead to overfitting, especially if the training dataset is limited. </li>
<li>Larger networks have higher computational complexity, making them difficult to apply.</li>
<li>As networks get deeper, the gradient becomes more prone to vanishing (gradient dispersion) as 
it travels back, making the model difficult to optimize.</li>
</ul>
<h2 id="what-is-vanishing-gradient-and-exploding-gradient">What Is Vanishing Gradient and Exploding gradient?<a class="headerlink" href="#what-is-vanishing-gradient-and-exploding-gradient" title="Permanent link"></a></h2>
<p>We know that in very deep networks, if the parameter initialization typically starts closer to zero. 
As a result, during training, the gradient tends to vanish as it propagates 
through the deeper layers of the network. 
This vanishing gradient problem prevents the parameters of the shallow layers from being updated effectively.</p>
<p>All in all, the any so-called AI is just $wx + b$. To illustrate,, let us consider the simplest AI model. We denote the mapping by $\phi$ and the intermediate variable by $z_i$
$$x_i = \phi(x_{i-1}) = \sigma(z_i) = \sigma(w_i x_{i-1} + b_i)$$ and our loss function by $\mathcal{L}$</p>
<div class="mermaid">
graph LR
  A(($x_0$)) -->|$\phi$| B(($x_1$))
  B(($x_1$)) -->|$\phi$| C(($x_2$))
  C(($x_2$)) -->|$\phi$| D(($x_3$))
  D(($x_3$)) -->|$\phi$| E(($x_4$))
</div>

<p>$$z_1 = w_1x_0 + b_1, x_1 = \sigma(z_1)$$
$$z_2 = w_2x_1 + b_2, x_2 = \sigma(z_2)$$
$$z_3 = w_3x_2 + b_3, x_3 = \sigma(z_3)$$
$$z_4 = w_4x_3 + b_4, x_4 = \sigma(z_4)$$</p>
<p>Let us take drivative with respect to $b_1$</p>
<p>$$\dfrac{\partial\mathcal{L}}{\partial b_1} =\dfrac{\partial \mathcal{L}}{\partial \sigma(z_4)} \dfrac{\partial \sigma}{\partial z_4}w_4 \dfrac{\partial \sigma}{\partial z_3}w_3 \dfrac{\partial \sigma}{\partial z_2} w_2  \dfrac{\partial \sigma}{\partial z_1}  $$</p>
<p>If the initial values of $w_2$, $w_3$, and $w_4$ are less than one and close to zero, the derivative with respect to $b_1$ will be close to zero, leading to the vanishing gradient problem.</p>
<p>On the contrary, the exploding gradient problem occurs when the absoluate values of the $w_2$, $w_3$, and $w_4$ are much greater than one. After thousands of multiplications, the values can become extremely large til NaN.</p>
<h2 id="what-is-the-network-degradation-problem-fail-to-learn-identity-mapping">What Is the Network Degradation Problem? Fail to Learn Identity Mapping<a class="headerlink" href="#what-is-the-network-degradation-problem-fail-to-learn-identity-mapping" title="Permanent link"></a></h2>
<p>To illustrate the network degradation problem, consider an optimal neural network with 18 layers. Often, when designing neural network architectures, the optimal number of layers is not known in advance. Suppose we then create a network with 34 layers. The extra 16 layers in this design are redundant. Ideally, we would like the model to learn to make these 16 additional layers act as identity mappings, meaning the input to these layers should match the output exactly. However, in practice, it is difficult for the model to learn these identity mappings correctly for the additional layers. Consequently, the 34-layer network&rsquo;s performance may end up being inferior to the 18-layer network. This drop in performance with increased network depth is referred to as the network degradation problem. This issue arises not from overfitting but from the inability of the redundant layers to correctly learn identity mappings. The idea of residual link is simply create an identity link for the model. And the amount of information flew through the pre-determined identity link or through network structure will be learned. </p>
<p>Learning identity mapping, $F(x)=x$, can be challenging for deep networks. Residual link addresses this issue by avoiding the direct learning of the identity mapping. Instead, it focuses on learning the residual function $F(x)=0$, which is much easier. This is because the initial weights in each layer are typically close to zero, making the learning process more straightforward. The idea here is not new and is commonly used when solving basic probability problems in textbooks. When solving a problem directly is difficult, we often approach it by considering the opposite side.</p>
<h2 id="why-does-residual-link-work">Why Does Residual Link Work?<a class="headerlink" href="#why-does-residual-link-work" title="Permanent link"></a></h2>
<p>I will use the previous example to illustrate idea. Recall our AI model:
$$z_1 = w_1x_0 + b_1, x_1 = \sigma(z_1)$$
$$z_2 = w_2x_1 + b_2, x_2 = \sigma(z_2)$$
$$z_3 = w_3x_2 + b_3, x_3 = \sigma(z_3)$$
$$z_4 = w_4x_3 + b_4, x_4 = \sigma(z_4)$$
we will add a residual link, the model became </p>
<p>$$z_1 = w_1x_0 + b_1, x_1 = \sigma(z_1)$$
$$z_2 = w_2x_1 + b_2, x_2 = \sigma(z_2)$$
$$z_3 = w_3x_2 + x_2 + b_3, x_3 = \sigma(z_3)$$
$$z_4 = w_4x_3 + b_4, x_4 = \sigma(z_4)$$</p>
<p>Let us take drivative again with respect to $b_1$</p>
<p>$$\dfrac{\partial\mathcal{L}}{\partial b_1} =\dfrac{\partial \mathcal{L}}{\partial \sigma(z_4)} \dfrac{\partial \sigma}{\partial z_4}w_4 \dfrac{\partial \sigma}{\partial z_3} (w_3 + 1) \dfrac{\partial \sigma}{\partial z_2} w_2  \dfrac{\partial \sigma}{\partial z_1}  $$</p>
<p>We can see that by adding an extra term to the gradient, we ensure it remains larger. However, this also carries the risk of causing an exploding gradient if the added term is too large. Therefore, it&rsquo;s important to balance this by doing the following:</p>
<ul>
<li>Residual Connections: Allowing gradients to bypass certain layers can help maintain gradient flow and alleviate both vanishing and exploding gradient problems.</li>
<li>Batch/Layer Normalization: Normalizing the inputs of each layer can stabilize the learning process.</li>
<li>Gradient Clipping: Capping the gradients at a maximum value to prevent them from growing too large.</li>
<li>Of course a better intial guess</li>
</ul>
<p>Of course, these explanations are just the beginning and very shallow in understanding why residual connections seem to work so well. </p>
<h2 id="singularity-and-residual-link">Singularity and Residual Link<a class="headerlink" href="#singularity-and-residual-link" title="Permanent link"></a></h2>
<p>I find the singularity explanation even more compelling. From what I understand, the idea is similar to the issue encountered with singular Hessian matrices. We can add a small extra term to ensure it is non-singular. Avoding sigularitiy has always been a main concern in numerical analysis. Similarily, when we have zero weights in certain layers, it blocks the gradient flow before and after, making the model unidentifiable. By &ldquo;unidentifiable,&rdquo; I mean that multiple sets of trained weights yield the same loss function. Anyone with basic numerical analysis knowledge will realize that this unidentifiability causes the loss function to be flat with respect to certain dimensions, which can be very difficult to handle. Adding a residual link ensures that different values of the originally blocked weights result in different loss functions, making the model identifiable.</p>
<p>Please refer to the following paper for a more in-depth discussion: <a href="https://openreview.net/pdf/c9b399553a97dcf49910998bd5ee6246b67a4003.pdf">https://openreview.net/pdf/c9b399553a97dcf49910998bd5ee6246b67a4003.pdf</a></p></article></body></html>